{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPSmnf9+WEswKz6SoEYRyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/odenmehmet/DL_Project/blob/main/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G05nMypnn3-V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "img_size = (224, 224)  # ResNet için önerilen boyut\n",
        "\n",
        "# Veri setini indir ve otomatik olarak train/test böl\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "# Sınıf isimleri (etiket-id)\n",
        "class_names = ds_info.features['label'].names\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess(img, label):\n",
        "    img = tf.image.resize(img, img_size)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    return img, label\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = ds_train.map(preprocess).shuffle(1000).batch(batch_size).prefetch(AUTOTUNE)\n",
        "val_ds   = ds_test.map(preprocess).batch(batch_size).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "k2dvaqqXoGg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1)\n",
        "])\n"
      ],
      "metadata": {
        "id": "3P1DjwlKoljr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Bir batch (32'lik grup) görsel ve etiket al\n",
        "for images, labels in train_ds.take(1):\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for i in range(10):\n",
        "        plt.subplot(2,5,i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(\"tf_flowers veri setinden örnekler\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "8iPVtBHZon30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "base_model.trainable = False  # Başta sadece üst katmanları eğiteceğiz (freeze)\n"
      ],
      "metadata": {
        "id": "HioTe2XBo5op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = tf.keras.applications.resnet50.preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "dP6nsbompNiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "-REF-wfVpSG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=3, restore_best_weights=True\n",
        ")\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,                  # 10 epoch genellikle yeterli\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "IyeZT1PhpU61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "plt.legend(); plt.title('Kayıp (Loss)')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "plt.legend(); plt.title('Doğruluk (Accuracy)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UXHa2lW_pWCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(val_ds)\n",
        "print(f'Test doğruluğu: {test_acc*100:.2f}%')\n"
      ],
      "metadata": {
        "id": "OqZckcw9pZ9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tüm test verisi için tahmin al\n",
        "y_true = []\n",
        "y_pred = []\n",
        "images_list = []\n",
        "\n",
        "for images, labels in val_ds.unbatch().batch(1).take(10):  # İlk 10 örnek için\n",
        "    pred = model.predict(images)\n",
        "    y_true.append(labels.numpy()[0])\n",
        "    y_pred.append(np.argmax(pred, axis=1)[0])\n",
        "    images_list.append(images[0].numpy())\n",
        "\n",
        "plt.figure(figsize=(15,3))\n",
        "for i in range(10):\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.imshow(images_list[i].astype('uint8'))\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"G:{class_names[y_true[i]]}\\nT:{class_names[y_pred[i]]}\", fontsize=8)\n",
        "plt.suptitle(\"İlk 10 örnek - Gerçek (G) / Tahmin (T)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a4W7uw3wpa1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Tüm val_ds için gerçek ve tahmin değerleri topla\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in val_ds.unbatch().batch(1):\n",
        "    pred = model.predict(images)\n",
        "    y_true.append(labels.numpy()[0])\n",
        "    y_pred.append(np.argmax(pred, axis=1)[0])\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "plt.figure(figsize=(8,6))\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2TCxpBuUsosQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "TP = np.diag(cm)\n",
        "FP = cm.sum(axis=0) - TP\n",
        "FN = cm.sum(axis=1) - TP\n",
        "TN = []\n",
        "for i in range(num_classes):\n",
        "    temp = np.delete(cm, i, 0)    # i. satırı sil\n",
        "    temp = np.delete(temp, i, 1)  # i. sütunu sil\n",
        "    TN.append(temp.sum())\n",
        "TN = np.array(TN)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    print(f\"Sınıf: {class_names[i]}\")\n",
        "    print(f\" TP: {TP[i]}, FP: {FP[i]}, FN: {FN[i]}, TN: {TN[i]}\")\n",
        "    print(\"-\"*30)\n"
      ],
      "metadata": {
        "id": "Sw7czww5st-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for images, y in train_ds.unbatch().batch(32):\n",
        "    # Preprocess: resize ve augment zaten train_ds içinde\n",
        "    x = tf.keras.applications.resnet50.preprocess_input(images)\n",
        "    x = base_model(x, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    features.append(x.numpy())\n",
        "    labels.append(y.numpy())\n",
        "\n",
        "features = np.vstack(features)\n",
        "labels = np.hstack(labels)\n",
        "\n",
        "# Test setinde de aynısını uygula:\n",
        "features_test = []\n",
        "labels_test = []\n",
        "for images, y in val_ds.unbatch().batch(32):\n",
        "    x = tf.keras.applications.resnet50.preprocess_input(images)\n",
        "    x = base_model(x, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    features_test.append(x.numpy())\n",
        "    labels_test.append(y.numpy())\n",
        "\n",
        "features_test = np.vstack(features_test)\n",
        "labels_test = np.hstack(labels_test)\n",
        "\n",
        "# Klasik ML modeliyle eğit/test et\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC()\n",
        "svm.fit(features, labels)\n",
        "print(\"Train SVM accuracy:\", svm.score(features, labels))\n",
        "print(\"Test SVM accuracy:\", svm.score(features_test, labels_test))\n"
      ],
      "metadata": {
        "id": "B5aQjuKMteh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "features_2d = tsne.fit_transform(features)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "for i, name in enumerate(class_names):\n",
        "    idx = labels == i\n",
        "    plt.scatter(features_2d[idx, 0], features_2d[idx, 1], label=name, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title(\"t-SNE ile feature space (Eğitim verisi)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_vxGWUmBtf58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "features_2d_pca = pca.fit_transform(features)\n",
        "plt.figure(figsize=(10,7))\n",
        "for i, name in enumerate(class_names):\n",
        "    idx = labels == i\n",
        "    plt.scatter(features_2d_pca[idx, 0], features_2d_pca[idx, 1], label=name, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title(\"PCA ile feature space (Eğitim verisi)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vlE-wSuOt-e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "EUl9GwbGvOus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning: base_model'in son bloklarını eğitime aç\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3  # Çok uzun sürmesin, örnek için kısa bırak\n",
        ")\n"
      ],
      "metadata": {
        "id": "Xg_rukyxxTsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- FINE-TUNING'DEN SONRA TEKRAR OLUŞTUR ----\n",
        "base_model = model.get_layer(\"resnet50\")\n",
        "last_conv_layer_name = [layer.name for layer in base_model.layers if \"conv\" in layer.name][-1]\n",
        "print(\"Kullanılan son konv katmanı:\", last_conv_layer_name)\n",
        "feature_extractor = tf.keras.Model(\n",
        "    inputs=base_model.input,\n",
        "    outputs=base_model.get_layer(last_conv_layer_name).output\n",
        ")\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, feature_extractor, pred_index=None):\n",
        "    img_aug = model.layers[1](img_array, training=False)\n",
        "    img_prep = tf.keras.applications.resnet50.preprocess_input(img_aug)\n",
        "    img_prep = tf.convert_to_tensor(img_prep)\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs = feature_extractor(img_prep, training=False)  # <-- önemli!\n",
        "        tape.watch(conv_outputs)\n",
        "        predictions = model(img_array, training=False)             # <-- önemli!\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[0, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    print(\"grads is None?\", grads is None)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)) if grads is not None else tf.zeros([conv_outputs.shape[-1]])\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    denom = tf.math.reduce_max(heatmap)\n",
        "    if denom == 0:\n",
        "        denom = 1e-8\n",
        "    heatmap = tf.maximum(heatmap, 0) / denom\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# ---- TEST EDEN KISIM (Hiçbir şey değiştirmene gerek yok) ----\n",
        "for img, label in val_ds.unbatch().batch(1).take(1):\n",
        "    img_disp = np.clip(img[0].numpy(), 0, 255).astype('uint8')\n",
        "    plt.imshow(img_disp)\n",
        "    plt.title(f\"Gerçek: {class_names[label.numpy()[0]]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    heatmap = make_gradcam_heatmap(img, model, feature_extractor)\n",
        "    heatmap_resized = cv2.resize(heatmap, (img_disp.shape[1], img_disp.shape[0]))\n",
        "    plt.imshow(img_disp)\n",
        "    plt.imshow(heatmap_resized, cmap='jet', alpha=0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Grad-CAM ısı haritası\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KZG65p7ox-dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# 1. Ara model: base_model'in içinden son konv katmanın adını bul\n",
        "base_model = model.get_layer(\"resnet50\")\n",
        "last_conv_layer_name = [layer.name for layer in base_model.layers if \"conv\" in layer.name][-1]\n",
        "print(\"Kullanılan son konv katmanı:\", last_conv_layer_name)\n",
        "\n",
        "# 2. Feature extractor: base_model'in inputundan son konv katmanın çıkışına kadar model\n",
        "feature_extractor = tf.keras.Model(\n",
        "    inputs=base_model.input,\n",
        "    outputs=base_model.get_layer(last_conv_layer_name).output\n",
        ")\n",
        "\n",
        "# 3. Grad-CAM fonksiyonu (None, sıfıra bölme vb. hatalara karşı korumalı!)\n",
        "def make_gradcam_heatmap(img_array, model, feature_extractor, pred_index=None):\n",
        "    img_aug = model.layers[1](img_array, training=False)\n",
        "    img_prep = tf.keras.applications.resnet50.preprocess_input(img_aug)\n",
        "    img_prep = tf.convert_to_tensor(img_prep)\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs = feature_extractor(img_prep, training=False)  # <-- Burada\n",
        "        tape.watch(conv_outputs)\n",
        "        predictions = model(img_array, training=False)              # <-- Burada\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[0, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    print(\"grads is None?\", grads is None)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)) if grads is not None else tf.zeros([conv_outputs.shape[-1]])\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    denom = tf.math.reduce_max(heatmap)\n",
        "    if denom == 0:\n",
        "        denom = 1e-8\n",
        "    heatmap = tf.maximum(heatmap, 0) / denom\n",
        "    return heatmap.numpy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4. Görselleştirme örneği (bir görselde çalıştır)\n",
        "for img, label in val_ds.unbatch().batch(1).take(1):\n",
        "    # Görselleştirme için: float32 değerleri [0, 255]'e çek ve uint8 yap\n",
        "    img_disp = np.clip(img[0].numpy(), 0, 255).astype('uint8')\n",
        "    plt.imshow(img_disp)\n",
        "    plt.title(f\"Gerçek: {class_names[label.numpy()[0]]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Grad-CAM\n",
        "    heatmap = make_gradcam_heatmap(img, model, feature_extractor)\n",
        "\n",
        "    heatmap_resized = cv2.resize(heatmap, (img_disp.shape[1], img_disp.shape[0]))\n",
        "    plt.imshow(img_disp)\n",
        "    plt.imshow(heatmap_resized, cmap='jet', alpha=0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Grad-CAM ısı haritası\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Qtj6xb7dvKsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NjQpSvm-wMH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}